# ğŸ‘‹ Hi, I'm Sai Shiva Jakkula  
### Engineering Graduate | Aspiring Data Analyst  
Learning SQL, Python, Power BI & Data Visualization  

---

## ğŸŒ± About Me  
I am an Engineering graduate passionate about Data Analytics and turning raw data into meaningful insights.  
Iâ€™m learning SQL, Python, Excel, Power BI, Machine Learning, NumPy, Matplotlib, and Seaborn.  
My goal is to become a strong Data Analyst who can solve real-world problems using data.

ğŸ“« Reach me at: **www.linkedin.com/in/saishiva-jakkula-**

---

# ğŸš€ Major Projects 

## ğŸ“Œ 1. **Zomato Restaurant EDA Project (Python)**  
Analyzed Zomato restaurant data using Python.  
Cleaned messy data, handled missing values, explored ratings, cost patterns, cuisine popularity, and online-order impact.  
Created visualizations like bar charts, scatter plots, histograms & heatmaps to uncover customer behavior.  
**Skills:** Python, Pandas, Matplotlib, Seaborn, Data Cleaning, EDA  

---

## ğŸ“Œ 2. **Top Rated Movies â€“ Web Scraping & EDA**  
Scraped movie data (title, rating, popularity, release date, description) using web scraping tools.  
Cleaned and structured the extracted data, analyzed rating trends, vote counts, popularity, and language distribution.  
Created visualizations to understand what makes a top-rated movie.  
**Skills:** Web Scraping, Data Cleaning, Visualization, Pandas  

---

## ğŸ“Œ 3. **Early Prediction of Diabetes (Jan 2025 â€“ May 2025)**  
Built ML model using XGBoost & Random Forest to predict diabetes risk.  
Learned preprocessing, feature engineering, model tuning & evaluation.  
**Skills:** ML, Feature Engineering, Classification, XGBoost  

---

## ğŸ“Œ 4. **Mobile Price Prediction (Oct 2024 â€“ Dec 2024)**  
Created regression model to predict mobile prices based on brand, RAM, storage & specs.  
Performed feature selection, scaling, model comparison & optimization.  
**Skills:** Regression, EDA, Pandas, Scikit-Learn  

---

# ğŸ§¹ Web Scraping + Cleaning Huge Data (Simple English)

Web scraping helps us collect information automatically from websites.  
But raw scraped data is usually messy â€” it may have missing values, broken text, symbols, duplicates, and inconsistent formats.  

So I follow these simple steps:  

**âœ” Step 1: Extract the Data**  
Use Python libraries like `requests`, `BeautifulSoup`, or APIs to pull information such as titles, ratings, and descriptions.

**âœ” Step 2: Clean the Data**  
- Remove duplicates  
- Fix missing values  
- Convert data types (dates, numbers)  
- Clean text  
- Standardize column names  

**âœ” Step 3: Make It Ready for EDA**  
After cleaning, the dataset becomes neat and ready for:  
- Charts  
- Trend analysis  
- Insights  
- Machine learning  

This helps turn huge, unstructured data into something meaningful and easy to understand.

## ğŸ› ï¸ Tech Stack

### Languages & Analytics
![Python](https://img.shields.io/badge/-Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/-Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/-NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)

### Visualization Tools
![Matplotlib](https://img.shields.io/badge/-Matplotlib-11557C?style=for-the-badge&logo=matplotlib&logoColor=white)
![Seaborn](https://img.shields.io/badge/-Seaborn-5C92D1?style=for-the-badge)

### Databases
![MySQL](https://img.shields.io/badge/-MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white)
